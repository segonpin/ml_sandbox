# Notes

We can use different Random Forest implementations:

- XGBoost (its own interface)
- H2O:
  - XGBoost (with same parameters as before)
  - Random Forest
- scikit-learn:
  - https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html
  - https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html
  - https://scikit-learn.org/1.6/auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison.html#sphx-glr-auto-examples-ensemble-plot-forest-hist-grad-boosting-comparison-py
- LightGBM (Should be possible to do the same as with xgboost?)



